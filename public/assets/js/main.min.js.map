{"version":3,"sources":["assets/js/main.js"],"names":["$","async","window","on","vh","innerHeight","css","trigger","$video","document","querySelector","$canvas","ctx","getContext","streamObj","front","loadedDataHandler","camera","openCam","navigator","mediaDevices","getUserMedia","video","facingMode","width","ideal","height","then","stream","srcObject","removeEventListener","console","log","videoWidth","videoHeight","addEventListener","img","Image","src","faceMesh","FaceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","onResults","results","requestAnimationFrame","clearRect","save","translate","scale","drawImage","image","multiFaceLandmarks","landmarks","drawConnectors","FACEMESH_LIPS","color","length","minX","Infinity","minY","maxX","maxY","point","x","y","Math","min","max","faceWidth","innerWidth","topOfHead","imgW","restore","Camera","onFrame","send","start","catch","error","alert","message","name","getTracks","forEach","track","stop"],"mappings":"AAAAA,EAAEC,iBACED,EAAEE,QAAQC,GAAG,YAAa,WACtB,IAAIC,EAA0B,IAArBF,OAAOG,YAChBL,EAAE,QAAQM,IAAI,OAAQF,EAAK,QAC5BG,QAAQ,aAEX,MAAMC,EAASC,SAASC,cAAc,uBAChCC,EAAUF,SAASC,cAAc,wBACjCE,EAAMD,EAAQE,WAAW,MAC/B,IAAIC,EACAC,GAAQ,EACRC,EACAC,EAKJ,SAASC,IAELC,UAAUC,aAAaC,aAAa,CAChCC,MAAO,CACHC,WAAYR,EAAQ,OAAS,cAC7BS,MAAO,CAAEC,MAAO,MAChBC,OAAQ,CAAED,MAAO,SAEtBE,KAAK,SAAUC,GACdd,EAAYc,EACZpB,EAAOqB,UAAYD,EAGfZ,GACAR,EAAOsB,oBAAoB,aAAcd,GAG7CA,EAAoB,WAChBe,QAAQC,IAAI,cAGZrB,EAAQa,MAAQhB,EAAOyB,WACvBtB,EAAQe,OAASlB,EAAO0B,aAI5B1B,EAAO2B,iBAAiB,aAAcnB,GAAmB,GAEzD,MAAMoB,EAAM,IAAIC,MAChBD,EAAIE,IAAM,gCAEV,MAAMC,EAAW,IAAIC,SAAS,CAC1BC,WAAaC,wDAA8DA,MAG/EH,EAASI,WAAW,CAChBC,YAAa,EACbC,iBAAiB,EACjBC,uBAAwB,GACxBC,sBAAuB,KAG3BR,EAASS,UAET,SAAmBC,GACfC,sBAAsB,KAWlB,GATAtC,EAAIuC,UAAU,EAAG,EAAGxC,EAAQa,MAAOb,EAAQe,QAC3Cd,EAAIwC,OACArC,IAEAH,EAAIyC,UAAU1C,EAAQa,MAAO,GAC7BZ,EAAI0C,OAAO,EAAG,IAElB1C,EAAI2C,UAAUN,EAAQO,MAAO,EAAG,EAAG7C,EAAQa,MAAOb,EAAQe,QAEtDuB,EAAQQ,mBACR,IAAK,MAAMC,KAAaT,EAAQQ,mBAM5BE,eAAe/C,EAAK8C,EAAWE,cAAe,CAAEC,MAAO,YAI/D,GAAIZ,EAAQQ,oBAA0D,EAApCR,EAAQQ,mBAAmBK,OAAY,CACrE,IAAMJ,EAAYT,EAAQQ,mBAAmB,GAG7C,IAAIM,EAAOC,EAAAA,EAAUC,EAAOD,EAAAA,EAAUE,GAAQF,EAAAA,EAAUG,GAAQH,EAAAA,EAChE,IAAK,MAAMI,KAASV,EAAW,CAC3B,IAAMW,EAAID,EAAMC,EAAI1D,EAAQa,MACtB8C,EAAIF,EAAME,EAAI3D,EAAQe,OAC5BqC,EAAOQ,KAAKC,IAAIT,EAAMM,GACtBJ,EAAOM,KAAKC,IAAIP,EAAMK,GACtBJ,EAAOK,KAAKE,IAAIP,EAAMG,GACtBF,EAAOI,KAAKE,IAAIN,EAAMG,GAI1B,IAAMI,EAAYR,EAAOH,EAKnBT,EAHWoB,GADEP,EAAOF,IAIA/D,OAAOyE,WAAazE,OAAOG,aAI/CuE,EAAYlB,EAAU,IACtBW,EAAIO,EAAUP,EAAI1D,EAAQa,MAC1B8C,EAAIM,EAAUN,EAAI3D,EAAQe,OAE1BmD,EAAOH,EAAqB,GAARpB,EAE1B1C,EAAI2C,UAAUnB,EAAKiC,EAAIQ,EAAO,EAAGP,EAAIO,EAAMA,EAAMA,GAGrDjE,EAAIkE,cAIZ7D,EAAS,IAAI8D,OAAOvE,EAAQ,CACxBwE,QAAS/E,gBACCsC,EAAS0C,KAAK,CAAEzB,MAAOhD,KAEjCgB,MAAO,KACPE,OAAQ,KACRH,WAAYR,EAAQ,OAAS,gBAEjCE,EAAOiE,UACRC,MAAM,SAAUC,GACfC,MAAM,eAAgBD,EAAME,QAASF,EAAMG,QApHnDrE,IA6HAlB,EAAE,2BAA2BG,GAAG,QAAS,WACrCW,EAAU0E,YAAYC,QAAQC,GAASA,EAAMC,QACzC1E,GACAA,EAAO0E,OAEX5E,GAASA,EACTG","file":"main.min.js","sourcesContent":["$(async function () {\n    $(window).on('resize.vh', function () {\n        var vh = window.innerHeight * 0.01;\n        $('html').css('--vh', vh + 'px');\n    }).trigger('resize.vh');\n\n    const $video = document.querySelector('[data-camera-video]');\n    const $canvas = document.querySelector('[data-camera-canvas]');\n    const ctx = $canvas.getContext('2d');\n    let streamObj; // 預計用來存放 串流相關的物件(MediaStream)\n    let front = true;\n    let loadedDataHandler; // 全局變數存儲 loadeddata 事件處理程序\n    let camera;\n\n    // 開啟 webcam\n    openCam();\n\n    function openCam() {\n        // 開啟視訊鏡頭，瀏覽器會跳詢問視窗\n        navigator.mediaDevices.getUserMedia({\n            video: {\n                facingMode: front ? 'user' : 'environment',\n                width: { ideal: 2400 },\n                height: { ideal: 3200 }\n            }\n        }).then(function (stream) {\n            streamObj = stream;         // 將串流物件放在 streamObj 全域變數，方便後面關閉 webcam 時會用到\n            $video.srcObject = stream;  // video 標籤顯示 webcam 畫面\n\n            // 先移除之前的事件綁定\n            if (loadedDataHandler) {\n                $video.removeEventListener('loadeddata', loadedDataHandler);\n            }\n            // 重新定義並綁定 loadeddata 事件\n            loadedDataHandler = function () {\n                console.log('loadeddata');\n\n                // 將 video 標籤的影片寬高，顯示於 canvas 標籤上\n                $canvas.width = $video.videoWidth;\n                $canvas.height = $video.videoHeight;\n            };\n\n            // 綁定事件\n            $video.addEventListener('loadeddata', loadedDataHandler, false);\n\n            const img = new Image();\n            img.src = './assets/image/touch/logo.png'; // 你想顯示的圖片路徑\n\n            const faceMesh = new FaceMesh({\n                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,\n            });\n\n            faceMesh.setOptions({\n                maxNumFaces: 1,\n                refineLandmarks: true,\n                minDetectionConfidence: 0.5,\n                minTrackingConfidence: 0.5,\n            });\n\n            faceMesh.onResults(onResults);\n\n            function onResults(results) {\n                requestAnimationFrame(() => {\n                    // 清空Canvas\n                    ctx.clearRect(0, 0, $canvas.width, $canvas.height);\n                    ctx.save();\n                    if (front) {\n                        // 水平反轉\n                        ctx.translate($canvas.width, 0);\n                        ctx.scale(-1, 1);\n                    }\n                    ctx.drawImage(results.image, 0, 0, $canvas.width, $canvas.height);\n\n                    if (results.multiFaceLandmarks) {\n                        for (const landmarks of results.multiFaceLandmarks) {\n                            // drawConnectors(ctx, landmarks, FACEMESH_TESSELATION,\n                            //     { color: '#C0C0C070', lineWidth: 1 });\n                            // drawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYE, { color: '#FF3030' });\n                            // drawConnectors(ctx, landmarks, FACEMESH_LEFT_EYE, { color: '#30FF30' });\n                            // drawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, { color: '#E0E0E0' });\n                            drawConnectors(ctx, landmarks, FACEMESH_LIPS, { color: '#E0E0E0' });\n                        }\n                    }\n\n                    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\n                        const landmarks = results.multiFaceLandmarks[0];\n\n                        // 計算臉部的外接矩形範圍\n                        let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;\n                        for (const point of landmarks) {\n                            const x = point.x * $canvas.width;\n                            const y = point.y * $canvas.height;\n                            minX = Math.min(minX, x);\n                            minY = Math.min(minY, y);\n                            maxX = Math.max(maxX, x);\n                            maxY = Math.max(maxY, y);\n                        }\n\n                        // 計算臉部面積\n                        const faceWidth = maxX - minX;\n                        const faceHeight = maxY - minY;\n                        const faceArea = faceWidth * faceHeight;\n\n                        // 根據面積調整圖片大小，面積越大，頭越近\n                        const scale = faceArea / (window.innerWidth * window.innerHeight);\n                        // $('.text').text(scale);\n\n                        // 計算頭頂的座標\n                        const topOfHead = landmarks[10];\n                        const x = topOfHead.x * $canvas.width;\n                        const y = topOfHead.y * $canvas.height;\n\n                        const imgW = faceWidth + (scale * 10);\n                        // 根據比例繪製圖片\n                        ctx.drawImage(img, x - imgW / 2, y - imgW, imgW, imgW);\n                    }\n\n                    ctx.restore();\n                });\n            }\n\n            camera = new Camera($video, {\n                onFrame: async () => {\n                    await faceMesh.send({ image: $video });\n                },\n                width: 3024,\n                height: 2400,\n                facingMode: front ? 'user' : 'environment'\n            });\n            camera.start();\n        }).catch(function (error) {     // 若無法取得畫面，執行 catch\n            alert('取得相機訪問權限失敗: ', error.message, error.name);\n        });\n    }\n\n    // const aaa = new Promise((resolve, reject) => {\n\n    // })\n    // await aaa;\n\n    $('[data-camera-direction]').on('click', function () {\n        streamObj.getTracks().forEach(track => track.stop());\n        if (camera) {\n            camera.stop(); // 停止之前的 Camera\n        }\n        front = !front;\n        openCam();\n        // restartMediaPipeCamera(); // 重新啟動 MediaPipe Camera\n    });\n\n\n\n\n    // // 初始化並啟動 MediaPipe Camera\n    // function startMediaPipeCamera() {\n\n    // }\n\n    // // 停止並重新啟動 MediaPipe Camera\n    // function restartMediaPipeCamera() {\n    //     if (camera) {\n    //         camera.stop(); // 停止之前的 Camera\n    //     }\n    //     startMediaPipeCamera(); // 重新啟動\n    // }\n\n    // // 啟動 MediaPipe Camera\n    // startMediaPipeCamera();\n});"],"sourceRoot":"/"}